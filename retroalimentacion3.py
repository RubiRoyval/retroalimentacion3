# -*- coding: utf-8 -*-
"""retroalimentacion3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y7vCMTlYm3NsxiiCzVFJt8x7RoteypLj

Carga de las librerias necesarias para el análisis
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, ConfusionMatrixDisplay, classification_report
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer

"""Visualización de los datos"""

data = pd.read_csv('/content/data.csv')
print(data.head())

"""División del dataset en conjunto de entrenamiento (70% del total del dataset), de prueba (30% del total del dataset) y de validación (20% del conjunto de entrenamiento)"""

data = pd.read_csv('/content/data.csv')

X = data.drop('diagnosis', axis=1)
y = data['diagnosis']

imputer = SimpleImputer(strategy='mean')
X = imputer.fit_transform(X)

X_train_valid, X_test, y_train_valid, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size=0.2, random_state=42)

"""Visualización de la distribución de los datos los conjuntos de entrenamiento, validación y prueba. Decidí hacerlo para 'diagnosis' ya que era la columna en donde mejor se podía visualizar la distibución de los datos."""

feature_index = 2
feature_name = X.columns[feature_index] if hasattr(X, 'columns') else 'Feature ' + str(feature_index + 1)

# Graficar la distribución de la característica elegida
plt.figure(figsize=(12, 8))
plt.hist(X_train[:, feature_index], bins=30, alpha=0.5, label='Train', color='blue')
plt.hist(X_valid[:, feature_index], bins=30, alpha=0.5, label='Validation', color='orange')
plt.hist(X_test[:, feature_index], bins=30, alpha=0.5, label='Test', color='green')
plt.title(f'Distribución de los conjuntos')
plt.xlabel('Diagnosis')
plt.ylabel('Frecuencia')
plt.legend()
plt.show()

"""Imprimí una muestra para cada conjutno y observar su tamaño."""

print("Conjunto de Entrenamiento:")
print(y_train.shape)
print("\nConjunto de Validación:")
print(y_test.shape)
print("\nConjunto de Prueba:")
print(y_valid.shape)

"""Inicializar el clasificador, entrenar el modelo y realizar predicciones con el conjunto de entrenamiento. Visuazaliamos la evaluación del modelo con este conjunto"""

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

y_train_pred = knn.predict(X_train)

train_accuracy=accuracy_score(y_train, y_train_pred)

print("Validation Accuracy:", train_accuracy)
print("Validation Classification Report:\n", classification_report(y_train, y_train_pred))

"""Se realiza el mismo proceso pero ahora para el conjunto de validacion."""

y_valid_pred = knn.predict(X_valid)

valid_accuracy=accuracy_score(y_valid, y_valid_pred)

print("Validation Accuracy:", valid_accuracy)
print("Validation Classification Report:\n", classification_report(y_valid, y_valid_pred))

"""Se realiza el mismo proceso pero ahora para el conjunto de prueba."""

y_test_pred = knn.predict(X_test)

test_accuracy=accuracy_score(y_test, y_test_pred)

print("Test Accuracy:", test_accuracy)
print("Test Classification Report:\n", classification_report(y_test, y_test_pred))

"""Visualización de los tres precision para poder realizar el análisis."""

precisions = [0.78, 0.73, 0.72]
labels = ['Training', 'Validation', 'Test']

plt.figure(figsize=(8, 6))
plt.bar(labels, precisions, color=['blue', 'orange', 'green'])
plt.title('Precisión del Modelo en Diferentes Conjuntos')
plt.xlabel('Conjunto')
plt.ylabel('Precisión')
plt.ylim(0, 1)
plt.show()

"""Para poder analizar la varianza la voy a calcular y a visualizarla en un gráfico."""

variance_train_valid = train_accuracy - valid_accuracy
variance_train_test = train_accuracy - test_accuracy


plt.figure(figsize=(12, 6))
precisions = [train_accuracy, valid_accuracy, test_accuracy]
labels = ['Training', 'Validation', 'Test']

plt.bar(labels, precisions, color=['blue', 'orange', 'green'])
plt.title('Varianza del modelo')
plt.xlabel('Conjunto')
plt.ylabel('Precisión')
plt.ylim(0, 1)
plt.show()

print(f"Diferencia de Precisión entre Entrenamiento y Validación: {variance_train_valid:.2f}")
print(f"Diferencia de Precisión entre Entrenamiento y Prueba: {variance_train_test:.2f}")

"""Normalización de los datos para poder mejorar el modelo.

Estandarización
"""

scaler = StandardScaler()
X_train_norm = scaler.fit_transform(X_train)
X_test_norm = scaler.transform(X_test)

knn_norm = KNeighborsClassifier(n_neighbors=5)
knn_norm.fit(X_train_norm, y_train)

y_pred_norm = knn_norm.predict(X_test_norm)

print("Accuracy Estandarización:", accuracy_score(y_test, y_pred_norm))
print("Classification Report:\n", classification_report(y_test, y_pred_norm))

"""Normalización min-max"""

min_max_scaler = MinMaxScaler()

X_train_normmm = min_max_scaler.fit_transform(X_train)
X_test_normmm = scaler.transform(X_test)

knn_normmm = KNeighborsClassifier(n_neighbors=5)
knn_normmm.fit(X_train_normmm, y_train)

y_pred_normmm = knn_normmm.predict(X_test_normmm)

print("Accuracy normalizacion min-max:", accuracy_score(y_test, y_pred_normmm))
print("Classification Report:\n", classification_report(y_test, y_pred_normmm))

"""Normalización por escala de varianza"""

quantile_transformer = QuantileTransformer(output_distribution='uniform')
X_quantile_transformed = quantile_transformer.fit_transform(X_train)
X_test_quantile_transformed = quantile_transformer.transform(X_test)

knn_quantile = KNeighborsClassifier(n_neighbors=5)
knn_quantile.fit(X_quantile_transformed, y_train)

y_pred_quantile = knn_quantile.predict(X_test_quantile_transformed)

print("Accuracy normalización por escala de varianza:", accuracy_score(y_test, y_pred_quantile))
print("Classification Report:\n", classification_report(y_test, y_pred_quantile))

